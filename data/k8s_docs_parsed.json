[
  {
    "title": "Label",
    "content_type": "",
    "source_file": "label.md",
    "weight": "",
    "chunks": [
      "Tags objects with identifying attributes that are meaningful and relevant to users.\n\n<!--more--> \n\nLabels are key/value pairs that are attached to objects such as . They are used to organize and to select subsets of objects."
    ]
  },
  {
    "title": "Probe",
    "content_type": "",
    "source_file": "probe.md",
    "weight": "",
    "chunks": [
      "A check that the  periodically performs against a container that is \nrunning in a pod, that will define container's state and health and informing container's lifecycle.\n\n<!--more-->\n \nTo learn more, read [container probes](/docs/concepts/workloads/pods/pod-lifecycle/#container-probes)."
    ]
  },
  {
    "title": "LimitRange",
    "content_type": "",
    "source_file": "limitrange.md",
    "weight": "",
    "chunks": [
      "Constraints resource consumption per  or ,\nspecified for a particular .\n\n<!--more--> \n\nA [LimitRange](/docs/concepts/policy/limit-range/) either limits the quantity of \nthat can be created (for a particular resource type),\nor the amount of \nthat may be requested/consumed by individual containers or Pods within a namespace."
    ]
  },
  {
    "title": "Dynamic Resource Allocation",
    "content_type": "",
    "source_file": "dra.md",
    "weight": "",
    "chunks": [
      "A Kubernetes feature that lets you request and share resources among Pods.\nThese resources are often attached\n like hardware\naccelerators.\n\n<!--more-->\n\nWith DRA, device drivers and cluster admins define device _classes_ that are\navailable to _claim_ in workloads. Kubernetes allocates matching devices to\nspecific claims and places the corresponding Pods on nodes that can access the\nallocated devices."
    ]
  },
  {
    "title": "Platform Developer",
    "content_type": "",
    "source_file": "platform-developer.md",
    "weight": "",
    "chunks": [
      "A person who customizes the Kubernetes platform to fit the needs of their project.\n\n<!--more--> \n\nA platform developer may, for example, use [Custom Resources](/docs/concepts/extend-kubernetes/api-extension/custom-resources/) or\n[Extend the Kubernetes API with the aggregation layer](/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/)\nto add functionality to their instance of Kubernetes, specifically for their application.\nSome Platform Developers are also  and\ndevelop extensions which are contributed to the Kubernetes community.\nOthers develop closed-source commercial or site-specific extensions."
    ]
  },
  {
    "title": "Reviewer",
    "content_type": "",
    "source_file": "reviewer.md",
    "weight": "",
    "chunks": [
      "A person who reviews code for quality and correctness on some part of the project.\n\n<!--more--> \n\nReviewers are knowledgeable about both the codebase and software engineering principles. Reviewer status is scoped to a part of the codebase."
    ]
  },
  {
    "title": "CustomResourceDefinition",
    "content_type": "",
    "source_file": "customresourcedefinition.md",
    "weight": "",
    "chunks": [
      "A kind of  that defines a new custom API to add\nto your Kubernetes API server, without building a complete custom server.\n\n<!--more-->\n\nCustomResourceDefinitions let you extend the Kubernetes API for your environment if the built-in\n can't meet your needs."
    ]
  },
  {
    "title": "Upstream (disambiguation)",
    "content_type": "",
    "source_file": "upstream.md",
    "weight": "",
    "chunks": [
      "May refer to: core Kubernetes or the source repo from which a repo was forked.\n\n<!--more--> \n\n* In the **Kubernetes Community**: Conversations often use *upstream* to mean the core Kubernetes codebase, which the general ecosystem, other code, or third-party tools rely upon. For example, [community members](#term-member) may suggest that a feature is moved upstream so that it is in the core codebase instead of in a plugin or third-party tool.\n* In **GitHub** or **git**: The convention is to refer to a source repo as *upstream*, whereas the forked repo is considered *downstream*."
    ]
  },
  {
    "title": "Service Catalog",
    "content_type": "",
    "source_file": "service-catalog.md",
    "weight": "",
    "chunks": [
      "A former extension API that enabled applications running in Kubernetes clusters to easily use external managed software offerings, such as a datastore service offered by a cloud provider.\n\n<!--more--> \n\nIt provided a way to list, provision, and bind with external  without needing detailed knowledge about how those services would be created or managed."
    ]
  },
  {
    "title": "Admission Controller",
    "content_type": "",
    "source_file": "admission-controller.md",
    "weight": "",
    "chunks": [
      "A piece of code that intercepts requests to the Kubernetes API server prior to persistence of the object.\n\n<!--more-->\n\nAdmission controllers are configurable for the Kubernetes API server and may be \"validating\", \"mutating\", or\nboth. Any admission controller may reject the request. Mutating controllers may modify the objects they admit;\nvalidating controllers may not.\n\n* [Admission controllers in the Kubernetes documentation](/docs/reference/access-authn-authz/admission-controllers/)"
    ]
  },
  {
    "title": "Cluster Operations",
    "content_type": "",
    "source_file": "cluster-operations.md",
    "weight": "",
    "chunks": [
      "The work involved in managing a Kubernetes cluster: managing\nday-to-day operations, and co-ordinating upgrades.\n\n<!--more-->\n\n Examples of cluster operations work include: deploying new Nodes to\nscale the cluster; performing software upgrades; implementing security\ncontrols; adding or removing storage; configuring cluster networking;\nmanaging cluster-wide observability; and responding to events."
    ]
  },
  {
    "title": "Persistent Volume Claim",
    "content_type": "",
    "source_file": "persistent-volume-claim.md",
    "weight": "",
    "chunks": [
      "Claims storage  defined in a\n, so that the storage can be mounted as\na volume in a .\n\n<!--more--> \n\nSpecifies the amount of storage, how the storage will be accessed (read-only, read-write and/or exclusive) and how it is reclaimed (retained, recycled or deleted). Details of the storage itself are described in the PersistentVolume object."
    ]
  },
  {
    "title": "Contributor",
    "content_type": "",
    "source_file": "contributor.md",
    "weight": "",
    "chunks": [
      "Someone who donates code, documentation, or their time to help the Kubernetes project or community.\n\n<!--more--> \n\nContributions include pull requests (PRs), issues, feedback,  participation, or organizing community events."
    ]
  },
  {
    "title": "Endpoints",
    "content_type": "",
    "source_file": "endpoint.md",
    "weight": "",
    "chunks": [
      "An endpoint of a  is one of the  (or external servers) that implements the Service.\n\n<!--more-->\nFor Services with ,\nthe EndpointSlice controller will automatically create one or more {{<\nglossary_tooltip text=\"EndpointSlices\" term_id=\"endpoint-slice\" >}} giving the\nIP addresses of the selected endpoint Pods.\n\nEndpointSlices can also be created manually to indicate the endpoints of\nServices that have no selector specified."
    ]
  },
  {
    "title": "Immutable Infrastructure",
    "content_type": "",
    "source_file": "immutable-infrastructure.md",
    "weight": "",
    "chunks": [
      "Immutable Infrastructure refers to computer infrastructure (virtual machines, containers, network appliances) that cannot be changed once deployed.\n\n<!--more-->\n\nImmutability can be enforced by an automated process that overwrites unauthorized changes or through a system that won’t allow changes in the first place.\n are a good example of immutable infrastructure because persistent changes to containers\ncan only be made by creating a new version of the container or recreating the existing container from its image.",
      "By preventing or identifying unauthorized changes, immutable infrastructures make it easier to identify and mitigate security risks. \nOperating such a system becomes a lot more straightforward because administrators can make assumptions about it.\nAfter all, they know no one made mistakes or changes they forgot to communicate.\nImmutable infrastructure goes hand-in-hand with infrastructure as code where all automation needed\nto create infrastructure is stored in version control (such as Git).\nThis combination of immutability and version control means that there is a durable audit log of every authorized change to a system."
    ]
  },
  {
    "title": "ConfigMap",
    "content_type": "",
    "source_file": "configmap.md",
    "weight": "",
    "chunks": [
      "An API object used to store non-confidential data in key-value pairs.\n can consume ConfigMaps as\nenvironment variables, command-line arguments, or as configuration files in a\n.\n\n<!--more--> \n\nA ConfigMap allows you to decouple environment-specific configuration from your , so that your applications are easily portable."
    ]
  },
  {
    "title": "Extensions",
    "content_type": "",
    "source_file": "extensions.md",
    "weight": "",
    "chunks": [
      "Extensions are software components that extend and deeply integrate with Kubernetes to support new types of hardware.\n\n<!--more-->\n\nMany cluster administrators use a hosted or distribution instance of Kubernetes. These clusters\ncome with extensions pre-installed. As a result, most Kubernetes users will not need to install\n[extensions](/docs/concepts/extend-kubernetes/) and even fewer users will need to author new ones."
    ]
  },
  {
    "title": "etcd",
    "content_type": "",
    "source_file": "etcd.md",
    "weight": "",
    "chunks": [
      "Consistent and highly-available key value store used as Kubernetes' backing store for all cluster data.\n\n<!--more-->\n\nIf your Kubernetes cluster uses etcd as its backing store, make sure you have a\n[back up](/docs/tasks/administer-cluster/configure-upgrade-etcd/#backing-up-an-etcd-cluster) plan\nfor the data.\n\nYou can find in-depth information about etcd in the official [documentation](https://etcd.io/docs/)."
    ]
  },
  {
    "title": "HostAliases",
    "content_type": "",
    "source_file": "host-aliases.md",
    "weight": "",
    "chunks": [
      "A HostAliases is a mapping between the IP address and hostname to be injected into a 's hosts file.\n\n<!--more-->\n\n[HostAliases](/docs/reference/generated/kubernetes-api//#hostalias-v1-core) is an optional list of hostnames and IP addresses that will be injected into the Pod's hosts file if specified. This is only valid for non-hostNetwork Pods."
    ]
  },
  {
    "title": "Container network interface (CNI)",
    "content_type": "",
    "source_file": "cni.md",
    "weight": "",
    "chunks": [
      "Container network interface (CNI) plugins are a type of Network plugin that adheres to the appc/CNI specification.\n\n<!--more-->\n\n* For information on Kubernetes and CNI, see [**Network Plugins**](/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/)."
    ]
  },
  {
    "title": "Sidecar Container",
    "content_type": "",
    "source_file": "sidecar-container.md",
    "weight": "",
    "chunks": [
      "One or more  that are typically started before any app containers run.\n\n<!--more--> \n\nSidecar containers are like regular app containers, but with a different purpose: the sidecar provides a Pod-local service to the main app container.\nUnlike , sidecar containers\ncontinue running after Pod startup.\n\nRead [Sidecar containers](/docs/concepts/workloads/pods/sidecar-containers/) for more information."
    ]
  },
  {
    "title": "DeviceClass",
    "content_type": "",
    "source_file": "deviceclass.md",
    "weight": "",
    "chunks": [
      "A category of  in the\n cluster that can be used with dynamic resource allocation (DRA).\n\n<!--more-->\n\nAdministrators or device owners use DeviceClasses to define a set of devices\nthat can be claimed and used in workloads. Devices are claimed by creating\n\nthat filter for specific device parameters in a DeviceClass.\n\nFor more information, see\n[Dynamic Resource Allocation](/docs/concepts/scheduling-eviction/dynamic-resource-allocation/#deviceclass)"
    ]
  },
  {
    "title": "API server",
    "content_type": "",
    "source_file": "kube-apiserver.md",
    "weight": "",
    "chunks": [
      "The API server is a component of the Kubernetes\n that exposes the Kubernetes API.\nThe API server is the front end for the Kubernetes control plane.\n\n<!--more-->\n\nThe main implementation of a Kubernetes API server is [kube-apiserver](/docs/reference/generated/kube-apiserver/).\nkube-apiserver is designed to scale horizontally&mdash;that is, it scales by deploying more instances.\nYou can run several instances of kube-apiserver and balance traffic between those instances."
    ]
  },
  {
    "title": "Volume",
    "content_type": "",
    "source_file": "volume.md",
    "weight": "",
    "chunks": [
      "A directory containing data, accessible to the  in a .\n\n<!--more-->\n\nA Kubernetes volume lives as long as the Pod that encloses it. Consequently, a volume outlives any containers that run within the Pod, and data in the volume is preserved across container restarts.\n\nSee [storage](/docs/concepts/storage/) for more information."
    ]
  },
  {
    "title": "ResourceClaim",
    "content_type": "",
    "source_file": "resourceclaim.md",
    "weight": "",
    "chunks": [
      "Describes the resources that a workload needs, such as\n. ResourceClaims are\nused in\n[dynamic resource allocation (DRA)](/docs/concepts/scheduling-eviction/dynamic-resource-allocation/)\nto provide Pods with access to a specific resource.\n\n<!--more-->\n\nResourceClaims can be created by workload operators or generated by Kubernetes\nbased on a\n."
    ]
  },
  {
    "title": "Node-pressure eviction",
    "content_type": "",
    "source_file": "node-pressure-eviction.md",
    "weight": "",
    "chunks": [
      "Node-pressure eviction is the process by which the  proactively terminates\npods to reclaim \non nodes.\n\n<!--more-->\n\nThe kubelet monitors resources like CPU, memory, disk space, and filesystem \ninodes on your cluster's nodes. When one or more of these resources reach\nspecific consumption levels, the kubelet can proactively fail one or more pods\non the node to reclaim resources and prevent starvation. \n\nNode-pressure eviction is not the same as [API-initiated eviction](/docs/concepts/scheduling-eviction/api-eviction/)."
    ]
  },
  {
    "title": "Preemption",
    "content_type": "",
    "source_file": "preemption.md",
    "weight": "",
    "chunks": [
      "Preemption logic in Kubernetes helps a pending  to find a suitable  by evicting low priority Pods existing on that Node.\n\n<!--more-->\n\nIf a Pod cannot be scheduled, the scheduler tries to [preempt](/docs/concepts/scheduling-eviction/pod-priority-preemption/#preemption) lower priority Pods to make scheduling of the pending Pod possible."
    ]
  },
  {
    "title": "Container",
    "content_type": "",
    "source_file": "container.md",
    "weight": "",
    "chunks": [
      "A lightweight and portable executable image that contains software and all of its dependencies.\n\n<!--more--> \n\nContainers decouple applications from underlying host infrastructure to make deployment easier in different cloud or OS environments, and for easier scaling.\nThe applications that run inside containers are called containerized applications. The process of bundling these applications and their dependencies into a container image is called containerization."
    ]
  },
  {
    "title": "Cluster",
    "content_type": "",
    "source_file": "cluster.md",
    "weight": "",
    "chunks": [
      "A set of worker machines, called ,\nthat run containerized applications. Every cluster has at least one worker node.\n\n<!--more-->\nThe worker node(s) host the  that are\nthe components of the application workload. The\n manages the worker\nnodes and the Pods in the cluster. In production environments, the control plane usually\nruns across multiple computers and a cluster usually runs multiple nodes, providing\nfault-tolerance and high availability."
    ]
  },
  {
    "title": "Aggregation Layer",
    "content_type": "",
    "source_file": "aggregation-layer.md",
    "weight": "",
    "chunks": [
      "The aggregation layer lets you install additional Kubernetes-style APIs in your cluster.\n\n<!--more-->\n\nWhen you've configured the  to [support additional APIs](/docs/tasks/extend-kubernetes/configure-aggregation-layer/), you can add `APIService` objects to \"claim\" a URL path in the Kubernetes API."
    ]
  },
  {
    "title": "Master",
    "content_type": "",
    "source_file": "master.md",
    "weight": "",
    "chunks": [
      "Legacy term, used as synonym for  hosting the .\n\n<!--more-->\nThe term is still being used by some provisioning tools, such as , and managed services, to   with `kubernetes.io/role` and control placement of  ."
    ]
  },
  {
    "title": "Code Contributor",
    "content_type": "",
    "source_file": "code-contributor.md",
    "weight": "",
    "chunks": [
      "A person who develops and contributes code to the Kubernetes open source codebase.\n\n<!--more--> \n\nThey are also an active  who participates in one or more ."
    ]
  },
  {
    "title": "kube-controller-manager",
    "content_type": "",
    "source_file": "kube-controller-manager.md",
    "weight": "",
    "chunks": [
      "Control plane component that runs  processes.\n\n<!--more-->\n\nLogically, each  is a separate process, but to reduce complexity, they are all compiled into a single binary and run in a single process."
    ]
  },
  {
    "title": "CRI-O",
    "content_type": "",
    "source_file": "cri-o.md",
    "weight": "",
    "chunks": [
      "A tool that lets you use OCI container runtimes with Kubernetes CRI.\n\n<!--more-->\n\nCRI-O is an implementation of the \nto enable using \nruntimes that are compatible with the Open Container Initiative (OCI)\n[runtime spec](https://www.github.com/opencontainers/runtime-spec).\n\nDeploying CRI-O allows Kubernetes to use any OCI-compliant runtime as the container\nruntime for running , and to fetch\nOCI container images from remote registries."
    ]
  },
  {
    "title": "Secret",
    "content_type": "",
    "source_file": "secret.md",
    "weight": "",
    "chunks": [
      "Stores sensitive information, such as passwords, OAuth tokens, and SSH keys.\n\n<!--more-->\n\nSecrets give you more control over how sensitive information is used and reduces\nthe risk of accidental exposure. Secret values are encoded as base64 strings and\nare stored unencrypted by default, but can be configured to be\n[encrypted at rest](/docs/tasks/administer-cluster/encrypt-data/#ensure-all-secrets-are-encrypted).\n\nA  can reference the Secret in\na variety of ways, such as in a volume mount or as an environment variable.\nSecrets are designed for confidential data and\n[ConfigMaps](/docs/tasks/configure-pod-container/configure-pod-configmap/) are\ndesigned for non-confidential data."
    ]
  },
  {
    "title": "Downward API",
    "content_type": "",
    "source_file": "downward-api.md",
    "weight": "",
    "chunks": [
      "Kubernetes' mechanism to expose Pod and container field values to code running in a container.\n<!--more-->\nIt is sometimes useful for a container to have information about itself, without\nneeding to make changes to the container code that directly couple it to Kubernetes.\n\nThe Kubernetes downward API allows containers to consume information about themselves\nor their context in a Kubernetes cluster. Applications in containers can have\naccess to that information, without the application needing to act as a client of\nthe Kubernetes API.\n\nThere are two ways to expose Pod and container fields to a running container:",
      "There are two ways to expose Pod and container fields to a running container:\n\n- using [environment variables](/docs/tasks/inject-data-application/environment-variable-expose-pod-information/)\n- using [a `downwardAPI` volume](/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/)\n\nTogether, these two ways of exposing Pod and container fields are called the _downward API_."
    ]
  },
  {
    "title": "Cloud Native Computing Foundation (CNCF)",
    "content_type": "",
    "source_file": "cncf.md",
    "weight": "",
    "chunks": [
      "The Cloud Native Computing Foundation (CNCF) builds sustainable ecosystems and\n fosters a community around [projects](https://www.cncf.io/projects/) that\n orchestrate containers as part of a microservices architecture.\n\nKubernetes is a CNCF project.\n\n<!--more-->\n\nThe CNCF is a sub-foundation of [the Linux Foundation](https://www.linuxfoundation.org/).\nIts mission is to make cloud native computing ubiquitous."
    ]
  },
  {
    "title": "Application Architect",
    "content_type": "",
    "source_file": "application-architect.md",
    "weight": "",
    "chunks": [
      "A person responsible for the high-level design of an application.\n\n<!--more--> \n\nAn architect ensures that an app's implementation allows it to interact with its surrounding components in a scalable, maintainable way. Surrounding components include databases, logging infrastructure, and other microservices."
    ]
  },
  {
    "title": "kOps (Kubernetes Operations)",
    "content_type": "",
    "source_file": "kops.md",
    "weight": "",
    "chunks": [
      "`kOps` will not only help you create, destroy, upgrade and maintain production-grade, highly available, Kubernetes cluster, but it will also provision the necessary cloud infrastructure.\n\n<!--more--> \n\n\nAWS (Amazon Web Services) is currently officially supported, with DigitalOcean, GCE and OpenStack in beta support, and Azure in alpha.\n\n\n`kOps` is an automated provisioning system:\n  * Fully automated installation\n  * Uses DNS to identify clusters\n  * Self-healing: everything runs in Auto-Scaling Groups\n  * Multiple OS support (Amazon Linux, Debian, Flatcar, RHEL, Rocky and Ubuntu)\n  * High-Availability support\n  * Can directly provision, or generate terraform manifests"
    ]
  },
  {
    "title": "Container Environment Variables",
    "content_type": "",
    "source_file": "container-env-variables.md",
    "weight": "",
    "chunks": [
      "Container environment variables are name=value pairs that provide useful information into containers running in a \n\n<!--more-->\n\nContainer environment variables provide information that is required by the running containerized applications along with information about important related details to the . For example, file system details, information about the container itself, and other cluster resources such as service endpoints."
    ]
  },
  {
    "title": "Downstream (disambiguation)",
    "content_type": "",
    "source_file": "downstream.md",
    "weight": "",
    "chunks": [
      "May refer to: code in the Kubernetes ecosystem that depends upon the core Kubernetes codebase or a forked repo.\n\n<!--more--> \n\n* In the **Kubernetes Community**: Conversations often use *downstream* to mean the ecosystem, code, or third-party tools that rely on the core Kubernetes codebase. For example, a new feature in Kubernetes may be adopted by applications *downstream* to improve their functionality.\n* In **GitHub** or **git**: The convention is to refer to a forked repo as *downstream*, whereas the source repo is considered *upstream*."
    ]
  },
  {
    "title": "Network Policy",
    "content_type": "",
    "source_file": "network-policy.md",
    "weight": "",
    "chunks": [
      "A specification of how groups of Pods are allowed to communicate with each other and with other network endpoints.\n\n<!--more--> \n\nNetworkPolicies help you declaratively configure which Pods are allowed to connect to each other, which namespaces are allowed to communicate,\nand more specifically which port numbers to enforce each policy on. NetworkPolicy objects use \nto select Pods and define rules which specify what traffic is allowed to the selected Pods.\n\nNetworkPolicies are implemented by a supported network plugin provided by a network provider.\nBe aware that creating a NetworkPolicy object without a controller to implement it will have no effect."
    ]
  },
  {
    "title": "Pod Priority",
    "content_type": "",
    "source_file": "pod-priority.md",
    "weight": "",
    "chunks": [
      "Pod Priority indicates the importance of a  relative to other Pods.\n\n<!--more-->\n\n[Pod Priority](/docs/concepts/scheduling-eviction/pod-priority-preemption/#pod-priority) gives the ability to set scheduling priority of a Pod to be higher and lower than other Pods — an important feature for production clusters workload."
    ]
  },
  {
    "title": "Mixed Version Proxy (MVP)",
    "content_type": "",
    "source_file": "mixed-version-proxy.md",
    "weight": "",
    "chunks": [
      "Feature to let a kube-apiserver proxy a resource request to a different peer API server.\n\n<!--more-->\n\nWhen a cluster has multiple API servers running different versions of Kubernetes, this\nfeature enables \nrequests to be served by the correct API server.\n\nMVP is disabled by default and can be activated by enabling\nthe [feature gate](/docs/reference/command-line-tools-reference/feature-gates/) named `UnknownVersionInteroperabilityProxy` when \nthe  is started."
    ]
  },
  {
    "title": "Image",
    "content_type": "",
    "source_file": "image.md",
    "weight": "",
    "chunks": [
      "Stored instance of a  that holds a set of software needed to run an application.\n\n<!--more-->\n\nA way of packaging software that allows it to be stored in a container registry, pulled to a local system, and run as an application. Meta data is included in the image that can indicate what executable to run, who built it, and other information."
    ]
  },
  {
    "title": "Disruption",
    "content_type": "",
    "source_file": "disruption.md",
    "weight": "",
    "chunks": [
      "Disruptions are events that lead to one or more\n going out of service.\nA disruption has consequences for workload management ,\nsuch as , that rely on the affected\nPods.\n\n<!--more-->\n\nIf you, as cluster operator, destroy a Pod that belongs to an application,\nKubernetes terms that a _voluntary disruption_. If a Pod goes offline\nbecause of a Node failure, or an outage affecting a wider failure zone,\nKubernetes terms that an _involuntary disruption_.\n\nSee [Disruptions](/docs/concepts/workloads/pods/disruptions/) for more information."
    ]
  },
  {
    "title": "Device Plugin",
    "content_type": "",
    "source_file": "device-plugin.md",
    "weight": "",
    "chunks": [
      "Device plugins run on worker\n and provide\n with access to\ninfrastructure ,\nsuch as local hardware, that require vendor-specific initialization or setup\nsteps.\n\n<!--more-->\n\nDevice plugins advertise resources to the\n, so that workload\nPods can access hardware features that relate to the Node where that Pod is running.\nYou can deploy a device plugin as a ,\nor install the device plugin software directly on each target Node.\n\nSee\n[Device Plugins](/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/)\nfor more information."
    ]
  },
  {
    "title": "Shuffle-sharding",
    "content_type": "",
    "source_file": "shuffle-sharding.md",
    "weight": "",
    "chunks": [
      "A technique for assigning requests to queues that provides better isolation than hashing modulo the number of queues.\n\n<!--more--> \n\nWe are often concerned with insulating different flows of requests\nfrom each other, so that a high-intensity flow does not crowd out low-intensity flows.\nA simple way to put requests into queues is to hash some\ncharacteristics of the request, modulo the number of queues, to get\nthe index of the queue to use. The hash function uses as input\ncharacteristics of the request that align with flows. For example, in\nthe Internet this is often the 5-tuple of source and destination\naddress, protocol, and source and destination port.",
      "That simple hash-based scheme has the property that any high-intensity flow\nwill crowd out all the low-intensity flows that hash to the same queue.\nProviding good insulation for a large number of flows requires a large\nnumber of queues, which is problematic. Shuffle-sharding is a more\nnimble technique that can do a better job of insulating the low-intensity\nflows from the high-intensity flows. The terminology of shuffle-sharding uses\nthe metaphor of dealing a hand from a deck of cards; each queue is a\nmetaphorical card. The shuffle-sharding technique starts with hashing\nthe flow-identifying characteristics of the request, to produce a hash\nvalue with dozens or more of bits. Then the hash value is used as a\nsource of entropy to shuffle the deck and deal a hand of cards",
      "source of entropy to shuffle the deck and deal a hand of cards\n(queues). All the dealt queues are examined, and the request is put\ninto one of the examined queues with the shortest length. With a\nmodest hand size, it does not cost much to examine all the dealt cards\nand a given low-intensity flow has a good chance to dodge the effects of a\ngiven high-intensity flow. With a large hand size it is expensive to examine\nthe dealt queues and more difficult for the low-intensity flows to dodge the\ncollective effects of a set of high-intensity flows. Thus, the hand size\nshould be chosen judiciously."
    ]
  },
  {
    "title": "Toleration",
    "content_type": "",
    "source_file": "toleration.md",
    "weight": "",
    "chunks": [
      "A core object consisting of three required properties: key, value, and effect. Tolerations enable the scheduling of pods on nodes or node groups that have matching .\n\n<!--more-->\n\nTolerations and  work together to ensure that pods are not scheduled onto inappropriate nodes. One or more tolerations are applied to a . A toleration indicates that the  is allowed (but not required) to be scheduled on nodes or node groups with matching ."
    ]
  },
  {
    "title": "UID",
    "content_type": "",
    "source_file": "uid.md",
    "weight": "",
    "chunks": [
      "A Kubernetes systems-generated string to uniquely identify objects.\n\n<!--more--> \n\nEvery object created over the whole lifetime of a Kubernetes cluster has a distinct UID. It is intended to distinguish between historical occurrences of similar entities."
    ]
  },
  {
    "title": "Pod Disruption",
    "content_type": "",
    "source_file": "pod-disruption.md",
    "weight": "",
    "chunks": [
      "[Pod disruption](/docs/concepts/workloads/pods/disruptions/) is the process by which \nPods on Nodes are terminated either voluntarily or involuntarily. \n\n<!--more--> \n\nVoluntary disruptions are started intentionally by application owners or cluster \nadministrators. Involuntary disruptions are unintentional and can be triggered by \nunavoidable issues like Nodes running out of ,\nor by accidental deletions."
    ]
  },
  {
    "title": "Horizontal Pod Autoscaler",
    "content_type": "",
    "source_file": "horizontal-pod-autoscaler.md",
    "weight": "",
    "chunks": [
      "An  that automatically scales the number of  replicas,\nbased on targeted  utilization or custom metric targets.\n\n<!--more--> \n\nHorizontalPodAutoscaler (HPA) is typically used with , or . It cannot be applied to objects that cannot be scaled, for example ."
    ]
  },
  {
    "title": "Cloud Provider",
    "content_type": "",
    "source_file": "cloud-provider.md",
    "weight": "",
    "chunks": [
      "A business or other organization that offers a cloud computing platform.\n\n<!--more-->\n\nCloud providers, sometimes called Cloud Service Providers (CSPs), offer\ncloud computing platforms or services.\n\nMany cloud providers offer managed infrastructure (also called\nInfrastructure as a Service or IaaS).\nWith managed infrastructure the cloud provider is responsible for\nservers, storage, and networking while you manage layers on top of that\nsuch as running a Kubernetes cluster.\n\nYou can also find Kubernetes as a managed service; sometimes called\nPlatform as a Service, or PaaS. With managed Kubernetes, your\ncloud provider is responsible for the Kubernetes control plane as well\nas the  and the\ninfrastructure they rely on: networking, storage, and possibly other\nelements such as load balancers."
    ]
  },
  {
    "title": "Kubernetes API",
    "content_type": "",
    "source_file": "kubernetes-api.md",
    "weight": "",
    "chunks": [
      "The application that serves Kubernetes functionality through a RESTful interface and stores the state of the cluster.\n\n<!--more--> \n\nKubernetes resources and \"records of intent\" are all stored as API objects, and modified via RESTful calls to the API. The API allows configuration to be managed in a declarative way. Users can interact with the Kubernetes API directly, or via tools like `kubectl`. The core Kubernetes API is flexible and can also be extended to support custom resources."
    ]
  },
  {
    "title": "Cluster Operator",
    "content_type": "",
    "source_file": "cluster-operator.md",
    "weight": "",
    "chunks": [
      "A person who configures, controls, and monitors clusters.\n\n<!--more--> \n\nTheir primary responsibility is keeping a cluster up and running, which may involve periodic maintenance activities or upgrades.<br>\n\n\nCluster operators are different from the [Operator pattern](/docs/concepts/extend-kubernetes/operator/) that extends the Kubernetes API."
    ]
  },
  {
    "title": "Control Plane",
    "content_type": "",
    "source_file": "control-plane.md",
    "weight": "",
    "chunks": [
      "The container orchestration layer that exposes the API and interfaces to define, deploy, and manage the lifecycle of containers.\n\n <!--more--> \n \n This layer is composed by many different components, such as (but not restricted to):\n\n * \n * \n * \n * \n * \n\n These components can be run as traditional operating system services (daemons) or as containers. The hosts running these components were historically called ."
    ]
  },
  {
    "title": "kube-proxy",
    "content_type": "",
    "source_file": "kube-proxy.md",
    "weight": "",
    "chunks": [
      "kube-proxy is a network proxy that runs on each\n in your cluster,\nimplementing part of the Kubernetes\n concept.\n\n<!--more-->\n\n[kube-proxy](/docs/reference/command-line-tools-reference/kube-proxy/)\nmaintains network rules on nodes. These network rules allow network\ncommunication to your Pods from network sessions inside or outside of\nyour cluster.\n\nkube-proxy uses the operating system packet filtering layer if there is one\nand it's available. Otherwise, kube-proxy forwards the traffic itself."
    ]
  },
  {
    "title": "JSON Web Token (JWT)",
    "content_type": "",
    "source_file": "jwt.md",
    "weight": "",
    "chunks": [
      "A means of representing claims to be transferred between two parties.\n\n<!--more-->\n\nJWTs can be digitally signed and encrypted. Kubernetes uses JWTs as\nauthentication tokens to verify the identity of entities that want to perform\nactions in a cluster."
    ]
  },
  {
    "title": "Kubectl",
    "content_type": "",
    "source_file": "kubectl.md",
    "weight": "",
    "chunks": [
      "Command line tool for communicating with a Kubernetes cluster's\n,\nusing the Kubernetes API.\n\n<!--more--> \n\nYou can use `kubectl` to create, inspect, update, and delete Kubernetes objects.\n\n<!-- localization note: OK to omit the rest of this entry -->\nIn English, `kubectl` is (officially) pronounced /kjuːb/ /kənˈtɹəʊl/ (like \"cube control\")."
    ]
  },
  {
    "title": "Pod Lifecycle",
    "content_type": "",
    "source_file": "pod-lifecycle.md",
    "weight": "",
    "chunks": [
      "The sequence of states through which a Pod passes during its lifetime.\n\n<!--more--> \n\nThe [Pod Lifecycle](/docs/concepts/workloads/pods/pod-lifecycle/) is defined by the states or phases of a Pod. There are five possible Pod phases: Pending, Running, Succeeded, Failed, and Unknown. A high-level description of the Pod state is summarized in the [PodStatus](/docs/reference/generated/kubernetes-api//#podstatus-v1-core) `phase` field."
    ]
  },
  {
    "title": "CronJob",
    "content_type": "",
    "source_file": "cronjob.md",
    "weight": "",
    "chunks": [
      "Manages a [Job](/docs/concepts/workloads/controllers/job/) that runs on a periodic schedule.\n\n<!--more-->\n\nSimilar to a line in a *crontab* file, a CronJob object specifies a schedule using the [cron](https://en.wikipedia.org/wiki/Cron) format."
    ]
  },
  {
    "title": "Quantity",
    "content_type": "",
    "source_file": "quantity.md",
    "weight": "",
    "chunks": [
      "A whole-number representation of small or large numbers using [SI](https://en.wikipedia.org/wiki/International_System_of_Units) suffixes.\n\n<!--more-->\n\nQuantities are representations of small or large numbers using a compact,\nwhole-number notation with SI suffixes.  Fractional numbers are represented\nusing milli units, while large numbers can be represented using kilo,\nmega, or giga units.\n\nFor instance, the number `1.5` is represented as `1500m`, while the number `1000`\ncan be represented as `1k`, and `1000000` as `1M`. You can also specify\n[binary-notation](https://en.wikipedia.org/wiki/Binary_prefix) suffixes; the number 2048 can be written as `2Ki`.",
      "The accepted decimal (power-of-10) units are `m` (milli), `k` (kilo,\nintentionally lowercase), `M` (mega), `G` (giga), `T` (tera), `P` (peta),\n`E` (exa).\n\nThe accepted binary (power-of-2) units are `Ki` (kibi), `Mi` (mebi), `Gi` (gibi),\n`Ti` (tebi), `Pi` (pebi), `Ei` (exbi)."
    ]
  },
  {
    "title": "Application Developer",
    "content_type": "",
    "source_file": "application-developer.md",
    "weight": "",
    "chunks": [
      "A person who writes an application that runs in a Kubernetes cluster.\n\n<!--more--> \n\nAn application developer focuses on one part of an application. The scale of their focus may vary significantly in size."
    ]
  },
  {
    "title": "Dockershim",
    "content_type": "",
    "source_file": "dockershim.md",
    "weight": "",
    "chunks": [
      "The dockershim is a component of Kubernetes version 1.23 and earlier. It allows the \nto communicate with .\n\n<!--more-->\n\nStarting with version 1.24, dockershim has been removed from Kubernetes. For more information, see [Dockershim FAQ](/dockershim)."
    ]
  },
  {
    "title": "sysctl",
    "content_type": "",
    "source_file": "sysctl.md",
    "weight": "",
    "chunks": [
      "`sysctl` is a semi-standardized interface for reading or changing the\n attributes of the running Unix kernel.\n\n<!--more-->\n\nOn Unix-like systems, `sysctl` is both the name of the tool that administrators\nuse to view and modify these settings, and also the system call that the tool\nuses.\n\n runtimes and\nnetwork plugins may rely on `sysctl` values being set a certain way."
    ]
  },
  {
    "title": "Node",
    "content_type": "",
    "source_file": "node.md",
    "weight": "",
    "chunks": [
      "A node is a worker machine in Kubernetes.\n\n<!--more-->\n\nA worker node may be a VM or physical machine, depending on the cluster. It has local daemons or services necessary to run  and is managed by the control plane. The daemons on a node include , , and a container runtime implementing the  such as .\n\nIn early Kubernetes versions, Nodes were called \"Minions\"."
    ]
  },
  {
    "title": "Watch",
    "content_type": "",
    "source_file": "watch.md",
    "weight": "",
    "chunks": [
      "A verb that is used to track changes to an object in Kubernetes as a stream.\nIt is used for the efficient detection of changes.\n\n<!--more-->\n\nA verb that is used to track changes to an object in Kubernetes as a stream. Watches allow\nefficient detection of changes; for example, a\n that needs to know whenever a\nConfigMap has changed can use a watch rather than polling.\n\nSee [Efficient Detection of Changes in API Concepts](/docs/reference/using-api/api-concepts/#efficient-detection-of-changes) for more information."
    ]
  },
  {
    "title": "ReplicationController",
    "content_type": "",
    "source_file": "replication-controller.md",
    "weight": "",
    "chunks": [
      "A workload management \nthat manages a replicated application, ensuring that\na specific number of instances of a  are running.\n\n<!--more-->\n\nThe control plane ensures that the defined number of Pods are running, even if some\nPods fail, if you delete Pods manually, or if too many are started by mistake.\n\n\nReplicationController is deprecated. See\n, which is similar."
    ]
  },
  {
    "title": "PriorityClass",
    "content_type": "",
    "source_file": "priority-class.md",
    "weight": "",
    "chunks": [
      "A PriorityClass is a named class for the scheduling priority that should be assigned to a Pod\nin that class.\n\n<!--more-->\n\nA [PriorityClass](/docs/concepts/scheduling-eviction/pod-priority-preemption/#how-to-use-priority-and-preemption)\nis a non-namespaced object mapping a name to an integer priority, used for a Pod. The name is\nspecified in the `metadata.name` field, and the priority value in the `value` field. Priorities range from\n-2147483648 to 1000000000 inclusive. Higher values indicate higher priority."
    ]
  },
  {
    "title": "FlexVolume",
    "content_type": "",
    "source_file": "flexvolume.md",
    "weight": "",
    "chunks": [
      "FlexVolume is a deprecated interface for creating out-of-tree volume plugins. The  is a newer interface that addresses several problems with FlexVolume.\n\n<!--more--> \n\nFlexVolumes enable users to write their own drivers and add support for their volumes in Kubernetes. FlexVolume driver binaries and dependencies must be installed on host machines. This requires root access. The Storage SIG suggests implementing a  driver if possible since it addresses the limitations with FlexVolumes.",
      "* [FlexVolume in the Kubernetes documentation](/docs/concepts/storage/volumes/#flexvolume)\n* [More information on FlexVolumes](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-storage/flexvolume.md)\n* [Volume Plugin FAQ for Storage Vendors](https://github.com/kubernetes/community/blob/master/sig-storage/volume-plugin-faq.md)"
    ]
  },
  {
    "title": "DaemonSet",
    "content_type": "",
    "source_file": "daemonset.md",
    "weight": "",
    "chunks": [
      "Ensures a copy of a  is running across a set of nodes in a .\n\n<!--more--> \n\nUsed to deploy system daemons such as log collectors and monitoring agents that typically must run on every ."
    ]
  },
  {
    "title": "Developer (disambiguation)",
    "content_type": "",
    "source_file": "developer.md",
    "weight": "",
    "chunks": [
      "May refer to&#58; , , or .\n\n<!--more--> \n\nThis overloaded term may have different meanings depending on the context"
    ]
  },
  {
    "title": "Feature gate",
    "content_type": "",
    "source_file": "feature-gates.md",
    "weight": "",
    "chunks": [
      "Feature gates are a set of keys (opaque string values) that you can use to control which\nKubernetes features are enabled in your cluster.\n\n<!--more-->\n\nYou can turn these features on or off using the `--feature-gates` command line flag on each Kubernetes component.\nEach Kubernetes component lets you enable or disable a set of feature gates that are relevant to that component.\nThe Kubernetes documentation lists all current \n[feature gates](/docs/reference/command-line-tools-reference/feature-gates/) and what they control."
    ]
  },
  {
    "title": "Operator pattern",
    "content_type": "",
    "source_file": "operator-pattern.md",
    "weight": "",
    "chunks": [
      "The [operator pattern](/docs/concepts/extend-kubernetes/operator/) is a system\ndesign that links a  to one or more custom\nresources.\n\n<!--more-->\n\nYou can extend Kubernetes by adding controllers to your cluster, beyond the built-in\ncontrollers that come as part of Kubernetes itself.\n\nIf a running application acts as a controller and has API access to carry out tasks\nagainst a custom resource that's defined in the control plane, that's an example of\nthe Operator pattern."
    ]
  },
  {
    "title": "Drain",
    "content_type": "",
    "source_file": "drain.md",
    "weight": "",
    "chunks": [
      "The process of safely evicting  from a  to prepare it for maintenance or removal from a .\n\n<!--more-->\n\nThe `kubectl drain` command is used to mark a  as going out of service. \nWhen executed, it evicts all  from the . \nIf an eviction request is temporarily rejected, `kubectl drain` retries until all  are terminated or a configurable timeout is reached."
    ]
  },
  {
    "title": "Name",
    "content_type": "",
    "source_file": "name.md",
    "weight": "",
    "chunks": [
      "A client-provided string that refers to an object in a \nURL, such as `/api/v1/pods/some-name`.\n\n<!--more--> \n\nOnly one object of a given kind can have a given name at a time. However, if you delete the object, you can make a new object with the same name."
    ]
  },
  {
    "title": "EndpointSlice",
    "content_type": "",
    "source_file": "endpoint-slice.md",
    "weight": "",
    "chunks": [
      "EndpointSlices track the IP addresses of Pods with matching  .\n\n<!--more-->\nEndpointSlices can be configured manually for  without selectors specified."
    ]
  },
  {
    "title": "Namespace",
    "content_type": "",
    "source_file": "namespace.md",
    "weight": "",
    "chunks": [
      "An abstraction used by Kubernetes to support isolation of groups of \nwithin a single .\n\n<!--more--> \n\nNamespaces are used to organize objects in a cluster and provide a way to divide cluster resources. Names of resources need to be unique within a namespace, but not across namespaces. Namespace-based scoping is applicable only for namespaced resources _(for example: Pods, Deployments, Services)_ and not for cluster-wide resources _(for example: StorageClasses, Nodes, PersistentVolumes)_."
    ]
  },
  {
    "title": "ResourceSlice",
    "content_type": "",
    "source_file": "resourceslice.md",
    "weight": "",
    "chunks": [
      "Represents one or more infrastructure resources, such as\n, that are attached to\nnodes. Drivers create and manage ResourceSlices in the cluster. ResourceSlices\nare used for\n[dynamic resource allocation (DRA)](/docs/concepts/scheduling-eviction/dynamic-resource-allocation/).\n\n<!--more-->\n\nWhen a  is\ncreated, Kubernetes uses ResourceSlices to find nodes that have access to\nresources that can satisfy the claim. Kubernetes allocates resources to the\nResourceClaim and schedules the Pod onto a node that can access the resources."
    ]
  },
  {
    "title": "Helm Chart",
    "content_type": "",
    "source_file": "helm-chart.md",
    "weight": "",
    "chunks": [
      "A package of pre-configured Kubernetes configurations that can be managed with the Helm tool.\n\n<!--more--> \n\nCharts provide a reproducible way of creating and sharing Kubernetes applications.\nA single chart can be used to deploy something simple, like a memcached Pod, or something complex, like a full web app stack with HTTP servers, databases, caches, and so on."
    ]
  },
  {
    "title": "QoS Class",
    "content_type": "",
    "source_file": "qos-class.md",
    "weight": "",
    "chunks": [
      "QoS Class (Quality of Service Class) provides a way for Kubernetes to classify Pods within the cluster into several classes and make decisions about scheduling and eviction.\n\n<!--more--> \nQoS Class of a Pod is set at creation time based on its \nrequests and limits settings. QoS classes are used to make decisions about Pods scheduling and eviction.\nKubernetes can assign one of the following  QoS classes to a Pod: `Guaranteed`, `Burstable` or `BestEffort`."
    ]
  },
  {
    "title": "PodTemplate",
    "content_type": "",
    "source_file": "pod-template.md",
    "weight": "",
    "chunks": [
      "An API object that defines a template for creating .\nThe PodTemplate API is also embedded in API definitions for workload management, such as \n or\n.\n\n<!--more--> \n\nPod templates allow you to define common metadata (such as labels, or a template for the name of a\nnew Pod) as well as to specify a pod's desired state.\n[Workload management](/docs/concepts/workloads/controllers/) controllers use Pod templates\n(embedded into another object, such as a Deployment or StatefulSet)\nto define and manage one or more .\nWhen there can be multiple Pods based on the same template, these are called\n.\nAlthough you can create a PodTemplate object directly, you rarely need to do so."
    ]
  },
  {
    "title": "Controller",
    "content_type": "",
    "source_file": "controller.md",
    "weight": "",
    "chunks": [
      "In Kubernetes, controllers are control loops that watch the state of your\n, then make or request\nchanges where needed.\nEach controller tries to move the current cluster state closer to the desired\nstate.\n\n<!--more-->\n\nControllers watch the shared state of your cluster through the\n (part of the\n).\n\nSome controllers also run inside the control plane, providing control loops that\nare core to Kubernetes' operations. For example: the deployment controller, the\ndaemonset controller, the namespace controller, and the persistent volume\ncontroller (and others) all run within the\n."
    ]
  },
  {
    "title": "Resource (infrastructure)",
    "content_type": "",
    "source_file": "infrastructure-resource.md",
    "weight": "",
    "chunks": [
      "Capabilities provided to one or more  (CPU, memory, GPUs, etc), and made available for consumption by\n running on those nodes.\n\nKubernetes also uses the term _resource_ to describe an .\n\n<!--more-->\nComputers provide fundamental hardware facilities: processing power, storage memory, network, etc.\nThese resources have finite capacity, measured in a unit applicable to that resource (number of CPUs, bytes of memory, etc).\nKubernetes abstracts common [resources](/docs/concepts/configuration/manage-resources-containers/)\nfor allocation to workloads and utilizes operating system primitives (for example, Linux ) to manage consumption by ).",
      "You can also use [dynamic resource allocation](/docs/concepts/scheduling-eviction/dynamic-resource-allocation/) to\nmanage complex resource allocations automatically."
    ]
  },
  {
    "title": "Kubeadm",
    "content_type": "",
    "source_file": "kubeadm.md",
    "weight": "",
    "chunks": [
      "A tool for quickly installing Kubernetes and setting up a secure cluster.\n\n<!--more--> \n\nYou can use kubeadm to install both the control plane and the  components."
    ]
  },
  {
    "title": "Istio",
    "content_type": "",
    "source_file": "istio.md",
    "weight": "",
    "chunks": [
      "An open platform (not Kubernetes-specific) that provides a uniform way to integrate microservices, manage traffic flow, enforce policies, and aggregate telemetry data.\n\n<!--more--> \n\nAdding Istio does not require changing application code. It is a layer of infrastructure between a service and the network, which when combined with service deployments, is commonly referred to as a service mesh. Istio's control plane abstracts away the underlying cluster management platform, which may be Kubernetes, Mesosphere, etc."
    ]
  },
  {
    "title": "containerd",
    "content_type": "",
    "source_file": "containerd.md",
    "weight": "",
    "chunks": [
      "A container runtime with an emphasis on simplicity, robustness and portability\n\n<!--more-->\n\ncontainerd is a  runtime\nthat runs as a daemon on Linux or Windows. containerd takes care of fetching and\nstoring container images, executing containers, providing network access, and more."
    ]
  },
  {
    "title": "Kubelet",
    "content_type": "",
    "source_file": "kubelet.md",
    "weight": "",
    "chunks": [
      "An agent that runs on each  in the cluster. It makes sure that  are running in a .\n\n<!--more-->\n\n\nThe [kubelet](/docs/reference/command-line-tools-reference/kubelet/) takes a set of PodSpecs that \nare provided through various mechanisms and ensures that the containers described in those \nPodSpecs are running and healthy. The kubelet doesn't manage containers which were not created by \nKubernetes."
    ]
  },
  {
    "title": "Garbage Collection",
    "content_type": "",
    "source_file": "garbage-collection.md",
    "weight": "",
    "chunks": [
      "Garbage collection is a collective term for the various mechanisms Kubernetes uses to clean up\ncluster resources. \n\n<!--more-->\n\nKubernetes uses garbage collection to clean up resources like\n[unused containers and images](/docs/concepts/architecture/garbage-collection/#containers-images),\n[failed Pods](/docs/concepts/workloads/pods/pod-lifecycle/#pod-garbage-collection),\n[objects owned by the targeted resource](/docs/concepts/overview/working-with-objects/owners-dependents/),\n[completed Jobs](/docs/concepts/workloads/controllers/ttlafterfinished/), and resources\nthat have expired or failed."
    ]
  },
  {
    "title": "Dynamic Volume Provisioning",
    "content_type": "",
    "source_file": "dynamic-volume-provisioning.md",
    "weight": "",
    "chunks": [
      "Allows users to request automatic creation of storage  .\n\n<!--more--> \n\nDynamic provisioning eliminates the need for cluster administrators to pre-provision storage. Instead, it automatically provisions storage by user request. Dynamic volume provisioning is based on an API object, , referring to a  that provisions a  and the set of parameters to pass to the Volume Plugin."
    ]
  },
  {
    "title": "cAdvisor",
    "content_type": "",
    "source_file": "cadvisor.md",
    "weight": "",
    "chunks": [
      "cAdvisor (Container Advisor) provides container users an understanding of the \nusage and performance characteristics of their running .\n\n<!--more-->\n\nIt is a running daemon that collects, aggregates, processes, and exports information about running containers. Specifically, for each container it keeps resource isolation parameters, historical resource usage, histograms of complete historical resource usage and network statistics. This data is exported by container and machine-wide."
    ]
  },
  {
    "title": "Object",
    "content_type": "",
    "source_file": "object.md",
    "weight": "",
    "chunks": [
      "An entity in the Kubernetes system. An object is an\n that the Kubernetes API\nuses to represent the state of your cluster.\n<!--more-->\nA Kubernetes object is typically a “record of intent”—once you create the object, the Kubernetes\n works constantly to ensure\nthat the item it represents actually exists.\nBy creating an object, you're effectively telling the Kubernetes system what you want that part of\nyour cluster's workload to look like; this is your cluster's desired state."
    ]
  },
  {
    "title": "Ephemeral Container",
    "content_type": "",
    "source_file": "ephemeral-container.md",
    "weight": "",
    "chunks": [
      "A  type that you can temporarily run inside a .\n\n<!--more-->\n\nIf you want to investigate a Pod that's running with problems, you can add an ephemeral container to that Pod and carry out diagnostics.\nEphemeral containers have no  or scheduling guarantees,\nand you should not use them to run any part of the workload itself.\n\nEphemeral containers are not supported by ."
    ]
  },
  {
    "title": "Volume Plugin",
    "content_type": "",
    "source_file": "volume-plugin.md",
    "weight": "",
    "chunks": [
      "A Volume Plugin enables integration of storage within a .\n\n<!--more--> \n\nA Volume Plugin lets you attach and mount storage volumes for use by a . Volume plugins can be _in tree_ or _out of tree_. _In tree_ plugins are part of the Kubernetes code repository and follow its release cycle. _Out of tree_ plugins are developed independently."
    ]
  },
  {
    "title": "ResourceClaimTemplate",
    "content_type": "",
    "source_file": "resourceclaimtemplate.md",
    "weight": "",
    "chunks": [
      "Defines a template that Kubernetes uses to create\n. \nResourceClaimTemplates are used in\n[dynamic resource allocation (DRA)](/docs/concepts/scheduling-eviction/dynamic-resource-allocation/)\nto provide _per-Pod access to separate, similar resources_.\n\n<!--more-->\n\nWhen a ResourceClaimTemplate is referenced in a workload specification,\nKubernetes automatically creates ResourceClaim objects based on the template.\nEach ResourceClaim is bound to a specific Pod. When the Pod terminates,\nKubernetes deletes the corresponding ResourceClaim."
    ]
  },
  {
    "title": "Manifest",
    "content_type": "",
    "source_file": "manifest.md",
    "weight": "",
    "chunks": [
      "Specification of a Kubernetes API object in [JSON](https://www.json.org/json-en.html)\nor [YAML](https://yaml.org/) format.\n\n<!--more-->\nA manifest specifies the desired state of an object that Kubernetes will maintain when you apply the manifest.\nFor YAML format, each file can contain multiple manifests."
    ]
  },
  {
    "title": "Finalizer",
    "content_type": "",
    "source_file": "finalizer.md",
    "weight": "",
    "chunks": [
      "Finalizers are namespaced keys that tell Kubernetes to wait until specific\nconditions are met before it fully deletes \nthat are marked for deletion.\nFinalizers alert \nto clean up resources the deleted object owned.\n\n<!--more-->",
      "<!--more-->\n\nWhen you tell Kubernetes to delete an object that has finalizers specified for\nit, the Kubernetes API marks the object for deletion by populating `.metadata.deletionTimestamp`,\nand returns a `202` status code (HTTP \"Accepted\"). The target object remains in a terminating state while the\ncontrol plane, or other components, take the actions defined by the finalizers.\nAfter these actions are complete, the controller removes the relevant finalizers\nfrom the target object. When the `metadata.finalizers` field is empty,\nKubernetes considers the deletion complete and deletes the object.\n\nYou can use finalizers to control \nof resources. For example, you can define a finalizer to clean up related\n or infrastructure before the controller\ndeletes the object being finalized."
    ]
  },
  {
    "title": "cgroup (control group)",
    "content_type": "",
    "source_file": "cgroup.md",
    "weight": "",
    "chunks": [
      "A group of Linux processes with optional  isolation, accounting and limits.\n\n<!--more--> \n\ncgroup is a Linux kernel feature that limits, accounts for, and isolates the resource usage (CPU, memory, disk I/O, network) for a collection of processes."
    ]
  },
  {
    "title": "Deployment",
    "content_type": "",
    "source_file": "deployment.md",
    "weight": "",
    "chunks": [
      "An API object that manages a replicated application, typically by running Pods with no local state.\n\n<!--more--> \n\nEach replica is represented by a , and the Pods are distributed among the \n of a cluster.\nFor workloads that do require local state, consider using a ."
    ]
  },
  {
    "title": "Certificate",
    "content_type": "",
    "source_file": "certificate.md",
    "weight": "",
    "chunks": [
      "A cryptographically secure file used to validate access to the Kubernetes cluster.\n\n<!--more--> \n\nCertificates enable applications within a Kubernetes cluster to access the Kubernetes API securely. Certificates validate that clients are allowed to access the API."
    ]
  },
  {
    "title": "Glossary",
    "content_type": "",
    "source_file": "index.md",
    "weight": 5,
    "chunks": []
  },
  {
    "title": "WG (working group)",
    "content_type": "",
    "source_file": "wg.md",
    "weight": "",
    "chunks": [
      "Facilitates the discussion and/or implementation of a short-lived, narrow, or decoupled project for a committee, , or cross-SIG effort.\n\n<!--more-->\n\nWorking groups are a way of organizing people to accomplish a discrete task.\n\nFor more information, see the [kubernetes/community](https://github.com/kubernetes/community) repo and the current list of [SIGs and working groups](https://github.com/kubernetes/community/blob/master/sig-list.md)."
    ]
  },
  {
    "title": "Logging",
    "content_type": "",
    "source_file": "logging.md",
    "weight": "",
    "chunks": [
      "Logs are the list of events that are logged by  or application.\n\n<!--more--> \n\nApplication and systems logs can help you understand what is happening inside your cluster. The logs are particularly useful for debugging problems and monitoring cluster activity."
    ]
  },
  {
    "title": "CLA (Contributor License Agreement)",
    "content_type": "",
    "source_file": "cla.md",
    "weight": "",
    "chunks": [
      "Terms under which a  grants a license to an open source project for their contributions.\n\n<!--more--> \n\nCLAs help resolve legal disputes involving contributed material and intellectual property (IP)."
    ]
  },
  {
    "title": "Cluster Infrastructure",
    "content_type": "",
    "source_file": "cluster-infrastructure.md",
    "weight": "",
    "chunks": [
      "The infrastructure layer provides and maintains VMs, networking, security groups and others."
    ]
  },
  {
    "title": "Taint",
    "content_type": "",
    "source_file": "taint.md",
    "weight": "",
    "chunks": [
      "A core object consisting of three required properties: key, value, and effect. Taints prevent the scheduling of  on  or node groups.\n\n<!--more-->\n\nTaints and  work together to ensure that pods are not scheduled onto inappropriate nodes. One or more taints are applied to a node. A node should only schedule a Pod with the matching tolerations for the configured taints."
    ]
  },
  {
    "title": "Managed Service",
    "content_type": "",
    "source_file": "managed-service.md",
    "weight": "",
    "chunks": [
      "A software offering maintained by a third-party provider.\n\n<!--more--> \n\nSome examples of Managed Services are AWS EC2, Azure SQL Database, and\nGCP Pub/Sub, but they can be any software offering that can be used by an application."
    ]
  },
  {
    "title": "Static Pod",
    "content_type": "",
    "source_file": "static-pod.md",
    "weight": "",
    "chunks": [
      "A  managed directly by the \n daemon on a specific node,\n<!--more-->\n\nwithout the API server observing it.\n\nStatic Pods do not support ."
    ]
  },
  {
    "title": "StatefulSet",
    "content_type": "",
    "source_file": "statefulset.md",
    "weight": "",
    "chunks": [
      "Manages the deployment and scaling of a set of , *and provides guarantees about the ordering and uniqueness* of these Pods.\n\n<!--more--> \n\nLike a , a StatefulSet manages Pods that are based on an identical container spec. Unlike a Deployment, a StatefulSet maintains a sticky identity for each of its Pods. These pods are created from the same spec, but are not interchangeable&#58; each has a persistent identifier that it maintains across any rescheduling.\n\nIf you want to use storage volumes to provide persistence for your workload, you can use a StatefulSet as part of the solution. Although individual Pods in a StatefulSet are susceptible to failure, the persistent Pod identifiers make it easier to match existing volumes to the new Pods that replace any that have failed."
    ]
  },
  {
    "title": "ResourceQuota",
    "content_type": "",
    "source_file": "resource-quota.md",
    "weight": "",
    "chunks": [
      "Object that constrains aggregate resource\nconsumption, per .\n\n<!--more-->\n\nA ResourceQuota can either limits the quantity of \nthat can be created in a namespace by type, or it can set a limit on the total amount of\n\nthat may be consumed on behalf of the namespace (and the objects within it)."
    ]
  },
  {
    "title": "user namespace",
    "content_type": "",
    "source_file": "userns.md",
    "weight": "",
    "chunks": [
      "A kernel feature to emulate root. Used for \"rootless containers\".\n\n<!--more-->\n\nUser namespaces are a Linux kernel feature that allows a non-root user to\nemulate superuser (\"root\") privileges,\nfor example in order to run containers without being a superuser outside the container.\n\nUser namespace is effective for mitigating damage of potential container break-out attacks.\n\nIn the context of user namespaces, the namespace is a Linux kernel feature, and not a\n in the Kubernetes sense\nof the term.\n\n<!-- TODO: https://kinvolk.io/blog/2020/12/improving-kubernetes-and-container-security-with-user-namespaces/ -->"
    ]
  },
  {
    "title": "Init Container",
    "content_type": "",
    "source_file": "init-container.md",
    "weight": "",
    "chunks": [
      "One or more initialization  that must run to completion before any app containers run.\n\n<!--more--> \n\nInitialization (init) containers are like regular app containers, with one difference: init containers must run to completion before any app containers can start. Init containers run in series: each init container must run to completion before the next init container begins.\n\nUnlike , init containers do not remain running after Pod startup.\n\nFor more information, read [init containers](/docs/concepts/workloads/pods/init-containers/)."
    ]
  },
  {
    "title": "Gateway API",
    "content_type": "",
    "source_file": "gateway.md",
    "weight": "",
    "chunks": [
      "A family of API kinds for modeling service networking in Kubernetes.\n\n<!--more--> \n\nGateway API provides a family of extensible, role-oriented, protocol-aware\nAPI kinds for modeling service networking in Kubernetes."
    ]
  },
  {
    "title": "Event",
    "content_type": "",
    "source_file": "event.md",
    "weight": "",
    "chunks": [
      "A Kubernetes  that describes state changes\nor notable occurrences in the cluster.\n\n<!--more-->\nEvents have a limited retention time and triggers and messages may evolve with time.\nEvent consumers should not rely on the timing of an event with a given reason reflecting a consistent underlying trigger,\nor the continued existence of events with that reason.\n\nEvents should be treated as informative, best-effort, supplemental data.\n\nIn Kubernetes, [auditing](/docs/tasks/debug/debug-cluster/audit/) generates a different kind of\nEvent record (API group `audit.k8s.io`)."
    ]
  },
  {
    "title": "Annotation",
    "content_type": "",
    "source_file": "annotation.md",
    "weight": "",
    "chunks": [
      "A key-value pair that is used to attach arbitrary non-identifying metadata to objects.\n\n<!--more--> \n\nThe metadata in an annotation can be small or large, structured or unstructured, and can include characters not permitted by . Clients such as tools and libraries can retrieve this metadata."
    ]
  },
  {
    "title": "API-initiated eviction",
    "content_type": "",
    "source_file": "api-eviction.md",
    "weight": "",
    "chunks": [
      "API-initiated eviction is the process by which you use the [Eviction API](/docs/reference/generated/kubernetes-api//#create-eviction-pod-v1-core)\nto create an `Eviction` object that triggers graceful pod termination.\n\n<!--more-->\n\nYou can request eviction either by directly calling the Eviction API \nusing a client of the kube-apiserver, like the `kubectl drain` command. \nWhen an `Eviction` object is created, the API server terminates the Pod. \n\nAPI-initiated evictions respect your configured [`PodDisruptionBudgets`](/docs/tasks/run-application/configure-pdb/)\nand [`terminationGracePeriodSeconds`](/docs/concepts/workloads/pods/pod-lifecycle#pod-termination).\n\nAPI-initiated eviction is not the same as [node-pressure eviction](/docs/concepts/scheduling-eviction/node-pressure-eviction/).",
      "* See [API-initiated eviction](/docs/concepts/scheduling-eviction/api-eviction/) for more information."
    ]
  },
  {
    "title": "Service",
    "content_type": "",
    "source_file": "service.md",
    "weight": "",
    "chunks": [
      "A method for exposing a network application that is running as one or more\n in your cluster.\n\n<!--more-->\n\nThe set of Pods targeted by a Service is (usually) determined by a\n. If more Pods are added or removed,\nthe set of Pods matching the selector will change. The Service makes sure that network traffic\ncan be directed to the current set of Pods for the workload.\n\nKubernetes Services either use IP networking (IPv4, IPv6, or both), or reference an external name in\nthe Domain Name System (DNS).\n\nThe Service abstraction enables other mechanisms, such as Ingress and Gateway."
    ]
  },
  {
    "title": "Security Context",
    "content_type": "",
    "source_file": "security-context.md",
    "weight": "",
    "chunks": [
      "The `securityContext` field defines privilege and access control settings for\na  or\n.\n\n<!--more-->\n\nIn a `securityContext`, you can define: the user that processes run as,\nthe group that processes run as, and privilege settings.\nYou can also configure security policies (for example: SELinux, AppArmor or seccomp).\n\nThe `PodSpec.securityContext` setting applies to all containers in a Pod."
    ]
  },
  {
    "title": "Eviction",
    "content_type": "",
    "source_file": "eviction.md",
    "weight": "",
    "chunks": [
      "Eviction is the process of terminating one or more Pods on Nodes.\n\n<!--more-->\nThere are two kinds of eviction:\n* [Node-pressure eviction](/docs/concepts/scheduling-eviction/node-pressure-eviction/)\n* [API-initiated eviction](/docs/concepts/scheduling-eviction/api-eviction/)"
    ]
  },
  {
    "title": "Minikube",
    "content_type": "",
    "source_file": "minikube.md",
    "weight": "",
    "chunks": [
      "A tool for running Kubernetes locally.\n\n<!--more--> \n\nMinikube runs an all-in-one or a multi-node local Kubernetes cluster inside a VM on your computer.\nYou can use Minikube to\n[try Kubernetes in a learning environment](/docs/tasks/tools/#minikube)."
    ]
  },
  {
    "title": "Spec",
    "content_type": "",
    "source_file": "spec.md",
    "weight": "",
    "chunks": [
      "Defines how each object, like Pods or Services, should be configured and its desired state.\n\n<!--more-->\nAlmost every Kubernetes object includes two nested object fields that govern the object's configuration: the object spec and the object status. For objects that have a spec, you have to set this when you create the object, providing a description of the characteristics you want the  to have: its desired state.\n\nIt varies for different objects like Pods, StatefulSets, and Services, detailing settings such as containers, volumes, replicas, ports,\nand other specifications unique to each object type. This field encapsulates what state Kubernetes should maintain for the defined\nobject."
    ]
  },
  {
    "title": "Cluster Architect",
    "content_type": "",
    "source_file": "cluster-architect.md",
    "weight": "",
    "chunks": [
      "A person who designs infrastructure that involves one or more Kubernetes clusters.\n\n<!--more--> \n\nCluster architects are concerned with best practices for distributed systems, for example&#58; high availability and security."
    ]
  },
  {
    "title": "Container Runtime",
    "content_type": "",
    "source_file": "container-runtime.md",
    "weight": "",
    "chunks": [
      "A fundamental component that empowers Kubernetes to run containers effectively.\n It is responsible for managing the execution and lifecycle of containers within the Kubernetes environment.\n\n<!--more-->\n\nKubernetes supports container runtimes such as\n, ,\nand any other implementation of the [Kubernetes CRI (Container Runtime\nInterface)](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md)."
    ]
  },
  {
    "title": "RBAC (Role-Based Access Control)",
    "content_type": "",
    "source_file": "rbac.md",
    "weight": "",
    "chunks": [
      "Manages authorization decisions, allowing admins to dynamically configure access policies through the .\n\n<!--more--> \n\nRBAC utilizes four kinds of Kubernetes objects:\n\nRole\n: Defines permission rules in a specific namespace.\n\nClusterRole\n: Defines permission rules cluster-wide.\n\nRoleBinding\n: Grants the permissions defined in a role to a set of users in a specific namespace.\n\nClusterRoleBinding\n: Grants the permissions defined in a role to a set of users cluster-wide.\n\nFor more information, see [RBAC](/docs/reference/access-authn-authz/rbac/)."
    ]
  },
  {
    "title": "Affinity",
    "content_type": "",
    "source_file": "affinity.md",
    "weight": "",
    "chunks": [
      "In Kubernetes, _affinity_ is a set of rules that give hints to the scheduler about where to place pods.\n\n<!--more-->\nThere are two kinds of affinity:\n* [node affinity](/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity)\n* [pod-to-pod affinity](/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity)\n\nThe rules are defined using the Kubernetes ,\nand  specified in , \nand they can be either required or preferred, depending on how strictly you want the scheduler to enforce them."
    ]
  },
  {
    "title": "Pod Security Policy",
    "content_type": "",
    "source_file": "pod-security-policy.md",
    "weight": "",
    "chunks": [
      "A former Kubernetes API that enforced security restrictions during  creation and updates.\n\n<!--more--> \n\nPodSecurityPolicy was deprecated as of Kubernetes v1.21, and removed in v1.25.\nAs an alternative, use [Pod Security Admission](/docs/concepts/security/pod-security-admission/) or a 3rd party admission plugin."
    ]
  },
  {
    "title": "Pod Disruption Budget",
    "content_type": "",
    "source_file": "pod-disruption-budget.md",
    "weight": "",
    "chunks": [
      "A [Pod Disruption Budget](/docs/concepts/workloads/pods/disruptions/) allows an \n application owner to create an object for a replicated application, that ensures \n a certain number or percentage of \n with an assigned label will not be voluntarily evicted at any point in time.\n\n<!--more--> \n\nInvoluntary disruptions cannot be prevented by PDBs; however they \ndo count against the budget."
    ]
  },
  {
    "title": "ReplicaSet",
    "content_type": "",
    "source_file": "replica-set.md",
    "weight": "",
    "chunks": [
      "A ReplicaSet (aims to) maintain a set of replica Pods running at any given time.\n\n<!--more-->\n\nWorkload objects such as  make use of ReplicaSets\nto ensure that the configured number of  are\nrunning in your cluster, based on the spec of that ReplicaSet."
    ]
  },
  {
    "title": "Pod",
    "content_type": "",
    "source_file": "pod.md",
    "weight": "",
    "chunks": [
      "The smallest and simplest Kubernetes object. A Pod represents a set of running  on your cluster.\n\n<!--more--> \n\nA Pod is typically set up to run a single primary container. It can also run optional sidecar containers that add supplementary features like logging. Pods are commonly managed by a ."
    ]
  },
  {
    "title": "Replica",
    "content_type": "",
    "source_file": "replica.md",
    "weight": "",
    "chunks": [
      "A copy or duplicate of a  or\na set of pods. Replicas ensure high availability, scalability, and fault tolerance\nby maintaining multiple identical instances of a pod.\n\n<!--more-->\nReplicas are commonly used in Kubernetes to achieve the desired application state and reliability.\nThey enable workload scaling and distribution across multiple nodes in a cluster.\n\nBy defining the number of replicas in a Deployment or ReplicaSet, Kubernetes ensures that\nthe specified number of instances are running, automatically adjusting the count as needed.\n\nReplica management allows for efficient load balancing, rolling updates, and\nself-healing capabilities in a Kubernetes cluster."
    ]
  },
  {
    "title": "API resource",
    "content_type": "",
    "source_file": "api-resource.md",
    "weight": "",
    "chunks": [
      "An entity in the Kubernetes type system, corresponding to an endpoint on the .\nA resource typically represents an .\nSome resources represent an operation on other objects, such as a permission check.\n<!--more-->\nEach resource represents an HTTP endpoint (URI) on the Kubernetes API server, defining the schema for the objects or operations on that resource."
    ]
  },
  {
    "title": "Member",
    "content_type": "",
    "source_file": "member.md",
    "weight": "",
    "chunks": [
      "A continuously active  in the K8s community.\n\n<!--more--> \n\nMembers can have issues and PRs assigned to them and participate in  through GitHub teams. Pre-submit tests are automatically run for members' PRs. A member is expected to remain an active contributor to the community."
    ]
  },
  {
    "title": "Cloud Controller Manager",
    "content_type": "",
    "source_file": "cloud-controller-manager.md",
    "weight": "",
    "chunks": [
      "A Kubernetes  component\nthat embeds cloud-specific control logic. The cloud controller manager lets you link your\ncluster into your cloud provider's API, and separates out the components that interact\nwith that cloud platform from components that only interact with your cluster.\n\n<!--more-->\n\nBy decoupling the interoperability logic between Kubernetes and the underlying cloud\ninfrastructure, the cloud-controller-manager component enables cloud providers to release\nfeatures at a different pace compared to the main Kubernetes project."
    ]
  },
  {
    "title": "Docker",
    "content_type": "",
    "source_file": "docker.md",
    "weight": "",
    "chunks": [
      "Docker (specifically, Docker Engine) is a software technology providing operating-system-level virtualization also known as .\n\n<!--more-->\n\nDocker uses the resource isolation features of the Linux kernel such as cgroups and kernel namespaces, and a union-capable file system such as OverlayFS and others to allow independent containers to run within a single Linux instance, avoiding the overhead of starting and maintaining virtual machines (VMs)."
    ]
  },
  {
    "title": "Workload",
    "content_type": "",
    "source_file": "workload.md",
    "weight": "",
    "chunks": [
      "A workload is an application running on Kubernetes.\n\n<!--more--> \n\nVarious core objects that represent different types or parts of a workload\ninclude the DaemonSet, Deployment, Job, ReplicaSet, and StatefulSet objects.\n\nFor example, a workload that has a web server and a database might run the\ndatabase in one  and the web server\nin a ."
    ]
  },
  {
    "title": "Common Expression Language",
    "content_type": "",
    "source_file": "cel.md",
    "weight": "",
    "chunks": [
      "A general-purpose expression language that's designed to be fast, portable, and\nsafe to execute.\n\n<!--more-->\n\nIn Kubernetes, CEL can be used to run queries and perform fine-grained\nfiltering. For example, you can use CEL expressions with\n[dynamic admission control](/docs/reference/access-authn-authz/extensible-admission-controllers/)\nto filter for specific fields in requests, and with\n[dynamic resource allocation (DRA)](/docs/concepts/scheduling-eviction/dynamic-resource-allocation)\nto select resources based on specific attributes."
    ]
  },
  {
    "title": "Data Plane",
    "content_type": "",
    "source_file": "data-plane.md",
    "weight": "",
    "chunks": [
      "The layer that provides capacity such as CPU, memory, network, and storage so that the containers can run and connect to a network."
    ]
  },
  {
    "title": "ServiceAccount",
    "content_type": "",
    "source_file": "service-account.md",
    "weight": "",
    "chunks": [
      "Provides an identity for processes that run in a .\n\n<!--more--> \n\nWhen processes inside Pods access the cluster, they are authenticated by the API server as a particular service account, for example, `default`. When you create a Pod, if you do not specify a service account, it is automatically assigned the default service account in the same ."
    ]
  },
  {
    "title": "Job",
    "content_type": "",
    "source_file": "job.md",
    "weight": "",
    "chunks": [
      "A finite or batch task that runs to completion.\n\n<!--more--> \n\nCreates one or more  objects and ensures that a specified number of them successfully terminate. As Pods successfully complete, the Job tracks the successful completions."
    ]
  },
  {
    "title": "Group Version Resource",
    "content_type": "",
    "source_file": "group-version-resource.md",
    "weight": "",
    "chunks": [
      "Means of representing specific Kubernetes APIs uniquely.\n\n<!--more-->\n\nGroup Version Resources (GVRs) specify the API group, API version, and _resource_ (name for the object kind as it appears in the URI) associated with accessing a particular id of object in Kubernetes.\nGVRs let you define and distinguish different Kubernetes objects, and to specify a way of accessing\nobjects that is stable even as APIs change.\n\nIn this usage, _resource_ refers to an HTTP resource. Because some APIs are namespaced, a GVR may\nnot refer to a specific ."
    ]
  },
  {
    "title": "Proxy",
    "content_type": "",
    "source_file": "proxy.md",
    "weight": "",
    "chunks": [
      "In computing, a proxy is a server that acts as an intermediary for a remote\nservice.\n\n<!--more-->\n\nA client interacts with the proxy; the proxy copies the client's data to the\nactual server; the actual server replies to the proxy; the proxy sends the\nactual server's reply to the client.\n\n[kube-proxy](/docs/reference/command-line-tools-reference/kube-proxy/) is a\nnetwork proxy that runs on each node in your cluster, implementing part of\nthe Kubernetes  concept.\n\nYou can run kube-proxy as a plain userland proxy service. If your operating\nsystem supports it, you can instead run kube-proxy in a hybrid mode that\nachieves the same overall effect using less system resources."
    ]
  },
  {
    "title": "kube-scheduler",
    "content_type": "",
    "source_file": "kube-scheduler.md",
    "weight": "",
    "chunks": [
      "Control plane component that watches for newly created\n with no assigned\n, and selects a node for them\nto run on.\n\n<!--more-->\n\nFactors taken into account for scheduling decisions include:\nindividual and collective \nrequirements, hardware/software/policy constraints, affinity and anti-affinity specifications,\ndata locality, inter-workload interference, and deadlines."
    ]
  },
  {
    "title": "Ingress",
    "content_type": "",
    "source_file": "ingress.md",
    "weight": "",
    "chunks": [
      "An API object that manages external access to the services in a cluster, typically HTTP.\n\n<!--more--> \n\nIngress may provide load balancing, SSL termination and name-based virtual hosting."
    ]
  },
  {
    "title": "Approver",
    "content_type": "",
    "source_file": "approver.md",
    "weight": "",
    "chunks": [
      "A person who can review and approve Kubernetes code contributions.\n\n<!--more--> \n\nWhile code review is focused on code quality and correctness, approval is focused on the holistic acceptance of a contribution. Holistic acceptance includes backwards/forwards compatibility, adhering to API and flag conventions, subtle performance and correctness issues, interactions with other parts of the system, and others. Approver status is scoped to a part of the codebase. Approvers were previously referred to as maintainers."
    ]
  },
  {
    "title": "Add-ons",
    "content_type": "",
    "source_file": "addons.md",
    "weight": "",
    "chunks": [
      "Resources that extend the functionality of Kubernetes.\n\n<!--more-->\n[Installing addons](/docs/concepts/cluster-administration/addons/) explains more about using add-ons with your cluster, and lists some popular add-ons."
    ]
  },
  {
    "title": "Device",
    "content_type": "",
    "source_file": "device.md",
    "weight": "",
    "chunks": [
      "One or more\n\nthat are directly or indirectly attached to your\n.\n\n<!--more-->\n\nDevices might be commercial products like GPUs, or custom hardware like\n[ASIC boards](https://en.wikipedia.org/wiki/Application-specific_integrated_circuit).\nAttached devices usually require device drivers that let Kubernetes\n access the devices."
    ]
  },
  {
    "title": "Container Lifecycle Hooks",
    "content_type": "",
    "source_file": "container-lifecycle-hooks.md",
    "weight": "",
    "chunks": [
      "The lifecycle hooks expose events in the  management lifecycle and let the user run code when the events occur.\n\n<!--more-->\n\nTwo hooks are exposed to Containers: PostStart which executes immediately after a container is created and PreStop which is blocking and is called immediately before a container is terminated."
    ]
  },
  {
    "title": "Mirror Pod",
    "content_type": "",
    "source_file": "mirror-pod.md",
    "weight": "",
    "chunks": [
      "A  object that a  uses\n to represent a \n\n<!--more--> \n\nWhen the kubelet finds a static pod in its configuration, it automatically tries to\ncreate a Pod object on the Kubernetes API server for it. This means that the pod\nwill be visible on the API server, but cannot be controlled from there.\n\n(For example, removing a mirror pod will not stop the kubelet daemon from running it)."
    ]
  },
  {
    "title": "App Container",
    "content_type": "",
    "source_file": "app-container.md",
    "weight": "",
    "chunks": [
      "Application containers (or app containers) are the  in a  that are started after any  have completed.\n\n<!--more-->\n\nAn init container lets you separate initialization details that are important for the overall \n, and that don't need to keep running\nonce the application container has started.\nIf a pod doesn't have any init containers configured, all the containers in that pod are app containers."
    ]
  },
  {
    "title": "Duration",
    "content_type": "",
    "source_file": "duration.md",
    "weight": "",
    "chunks": [
      "A string value representing an amount of time.\n\n<!--more-->\n\nThe format of a (Kubernetes) duration is based on the\n[`time.Duration`](https://pkg.go.dev/time#Duration) type from the Go programming language.\n\nIn Kubernetes APIs that use durations, the value is expressed as series of a non-negative\nintegers combined with a time unit suffix. You can have more than one time quantity and\nthe duration is the sum of those time quantities.\nThe valid time units are \"ns\", \"µs\" (or \"us\"), \"ms\", \"s\", \"m\", and \"h\".\n\nFor example: `5s` represents a duration of five seconds, and `1m30s` represents a duration\nof one minute and thirty seconds."
    ]
  },
  {
    "title": "API Group",
    "content_type": "",
    "source_file": "api-group.md",
    "weight": "",
    "chunks": [
      "A set of related paths in Kubernetes API.\n\n<!--more-->\n\nYou can enable or disable each API group by changing the configuration of your API server. You can also disable or enable paths to specific\n. An API group makes it easier to extend the Kubernetes API.\nThe API group is specified in a REST path and in the `apiVersion` field of a serialized .\n\n* Read [API Group](/docs/concepts/overview/kubernetes-api/#api-groups-and-versioning) for more information."
    ]
  },
  {
    "title": "Selector",
    "content_type": "",
    "source_file": "selector.md",
    "weight": "",
    "chunks": [
      "Allows users to filter a list of \n based on .\n\n<!--more--> \n\nSelectors are applied when querying lists of resources to filter them by labels."
    ]
  },
  {
    "title": "CIDR",
    "content_type": "",
    "source_file": "cidr.md",
    "weight": "",
    "chunks": [
      "CIDR (Classless Inter-Domain Routing) is a notation for describing blocks of IP addresses and is used heavily in various networking configurations.\n\n<!--more-->\n\nIn the context of Kubernetes, each  is assigned a range of IP addresses through the start address and a subnet mask using CIDR. This allows Nodes to assign each  a unique IP address. Although originally a concept for IPv4, CIDR has also been expanded to include IPv6."
    ]
  },
  {
    "title": "Container Runtime Interface (CRI)",
    "content_type": "",
    "source_file": "cri.md",
    "weight": "",
    "chunks": [
      "The main protocol for the communication between the  and Container Runtime.\n\n<!--more-->\n\nThe Kubernetes Container Runtime Interface (CRI) defines the main\n[gRPC](https://grpc.io) protocol for the communication between the\n[node components](/docs/concepts/architecture/#node-components)\n and\n."
    ]
  },
  {
    "title": "Container Storage Interface (CSI)",
    "content_type": "",
    "source_file": "csi.md",
    "weight": "",
    "chunks": [
      "The Container Storage Interface (CSI) defines a standard interface to expose storage systems to containers.\n\n<!--more--> \n\nCSI allows vendors to create custom storage plugins for Kubernetes without adding them to the Kubernetes repository (out-of-tree plugins). To use a CSI driver from a storage provider, you must first [deploy it to your cluster](https://kubernetes-csi.github.io/docs/deploying.html). You will then be able to create a  that uses that CSI driver.\n\n* [CSI in the Kubernetes documentation](/docs/concepts/storage/volumes/#csi)\n* [List of available CSI drivers](https://kubernetes-csi.github.io/docs/drivers.html)"
    ]
  },
  {
    "title": "Applications",
    "content_type": "",
    "source_file": "applications.md",
    "weight": "",
    "chunks": [
      "The layer where various containerized applications run."
    ]
  },
  {
    "title": "Storage Class",
    "content_type": "",
    "source_file": "storage-class.md",
    "weight": "",
    "chunks": [
      "A StorageClass provides a way for administrators to describe different available storage types.\n\n<!--more--> \n\nStorageClasses can map to quality-of-service levels, backup policies, or to arbitrary policies determined by cluster administrators. Each StorageClass contains the fields `provisioner`, `parameters`, and `reclaimPolicy`, which are used when a  belonging to the class needs to be dynamically provisioned. Users can request a particular class using the name of a StorageClass object."
    ]
  },
  {
    "title": "SIG (special interest group)",
    "content_type": "",
    "source_file": "sig.md",
    "weight": "",
    "chunks": [
      "who collectively manage an ongoing piece or aspect of the larger Kubernetes open source project.\n\n<!--more--> \n\nMembers within a SIG have a shared interest in advancing a specific area, such as architecture, API machinery, or documentation.\nSIGs must follow the SIG [governance guidelines](https://github.com/kubernetes/community/blob/master/committee-steering/governance/sig-governance.md), but can have their own contribution policy and channels of communication.\n\nFor more information, see the [kubernetes/community](https://github.com/kubernetes/community) repo and the current list of [SIGs and Working Groups](https://github.com/kubernetes/community/blob/master/sig-list.md)."
    ]
  },
  {
    "title": "Persistent Volume",
    "content_type": "",
    "source_file": "persistent-volume.md",
    "weight": "",
    "chunks": [
      "An API object that represents a piece of storage in the cluster. Representation of as a general, pluggable storage\n that can persist beyond the lifecycle of any\nindividual .\n\n<!--more--> \n\nPersistentVolumes (PVs) provide an API that abstracts details of how storage is provided from how it is consumed.\nPVs are used directly in scenarios where storage can be created ahead of time (static provisioning).\nFor scenarios that require on-demand storage (dynamic provisioning), PersistentVolumeClaims (PVCs) are used instead."
    ]
  }
]